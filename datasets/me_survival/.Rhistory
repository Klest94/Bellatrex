print(mean(a,na.rm=TRUE))
View(results_df)
View(results_df)
# tryout C443 package
rm(list = ls()) #clean everything first
setwd('C:/Users/u0135479/Documents/GitHub/Explain-extract-trees/R_folder_andC443')
datapath <- "C:/Users/u0135479/Documents/GitHub/Explain-extract-trees/datasets/binary/"
K <- 5 # K-folds
max.clusters = 3
N <- 100 # n trees
# test size: old_test = 50, new_test = 100
dnames <- list.files(path = datapath)
library(data.table)
library(MASS)
library(rpart)
library(C443)
library(pROC) # for the AUROC part
#library(PRROC) # for computing AUPR
#library(PerfMeas)
#Function to draw a bootstrap sample from a dataset
DrawBoots <- function(dataset, i){
set.seed(2394 + i)
Boot <- dataset[sample(1:nrow(dataset), size = nrow(dataset), replace = TRUE),]
return(Boot)
}
GrowTree <- function(x,y, BootsSample, minsplit = 5){
controlrpart <- rpart.control(minsplit = minsplit,
maxsurrogate = 0, maxcompete = 0)
tree <- rpart(as.formula(paste(noquote(paste(y, "~")), noquote(paste(x, collapse="+")))),
data = BootsSample, control = controlrpart)
return(tree)
}
SqrtVars <- function(dataset, i){
set.seed(2394 + i)
sqrt.bound <- ceiling(sqrt(ncol(dataset)))
dataset <- dataset[sample(ncol(dataset))] #shuffling columns
sqrt.cols <- dataset[1:sqrt.bound]
return(colnames(sqrt.cols))
}
ETrees <-function(df.test, clusts){
medoids.idx <- ClusterForest$medoids[[clusts]]
clusters.sizes <- table(ClusterForest$clusters[[clusts]])/N
y.test <- ifelse(df.test[, ncol(df.test)] == "Yes",1,0)
y.pred <- c(1:nrow(df.test))*0 # initialize with 0-s
for (sample in c(1:nrow(df.test))){
i <- 0
for (index in medoids.idx){
i <- i + 1
y.pred[sample] <- y.pred[sample] + (predict(Trees[[index]],
df.test[sample,])[2]*clusters.sizes[i]) # it's working
}
}
# now time to check performance
return(auc(roc(y.test, y.pred)))
}
#FIXED FOLDS (80% train. max 50 test samples) broken with: 1, 11, 18, 21, 22 ( or 1)
#FIXED FOLDS (80% train. max 100 test samples) broken with 1 only (?)
testing.names <- dnames[1:3]
results_all <- data.frame(data=NA, AUROC=NA, AUPR=NA) # empty dataframe to start with. Append here every FOLD
results_df <- data.frame(data=NA, AUROC=NA, AUPR=NA) # append avg. performacne only
auroc.fold <- c(1:K)*NaN
aupr.fold <- c(1:K)*NaN
for (folder in testing.names) {
for (k in 1:K){
print(paste("dataset:", folder, "loop fold:", k))
df.train <- read.csv(file = paste(datapath, folder, "/new_train",k, ".csv", sep= ''))
df.test <- read.csv(file = paste(datapath, folder, "/new_test", k, ".csv", sep= ''))
df <- rbind(df.train, df.test)
#print(folder)
#print(paste(datapath, folder, "/new_test", k, ".csv", sep= ''))
df.train[,ncol(df.train)] <- ifelse(df.train[,ncol(df.train)] == 1, "Yes", "No")
df.test[,ncol(df.train)] <- ifelse(df.test[,ncol(df.test)] == 1, "Yes", "No")
Boots<- lapply(1:N, function(k) DrawBoots(df.train ,k))
Trees <- lapply(1:N, function (i) GrowTree(
x = SqrtVars(df.train[-ncol(df.train)], i), #sample sqrt(ncols) variables for the split (excludes     target)
y = colnames(df.train)[ncol(df.train)],
Boots[[i]] ))
#ClusterForest<- clusterforest(fulldata=df.train, treedata=Boots, trees=Trees, m=1,
#                              fromclus=1, toclus=max.clusters)
tryCatch({
ClusterForest<- clusterforest(fulldata=df.train, treedata=Boots, trees=Trees, m=1,
fromclus=1, toclus=max.clusters)
medoids.idx <- ClusterForest$medoids[[max.clusters]]
clusters.sizes <- table(ClusterForest$clusters[max.clusters])/N
# WARNING: medoids indexes and cluster indexes are not synced
y.test <- ifelse(df.test[, ncol(df.test)] == "Yes",1,0)
df.labels = data.frame(y.test)
y.pred <- c(1:nrow(df.test))*0 # initialize with 0-s
for (sample in c(1:nrow(df.test))){
i <- 0
for (index in medoids.idx){
i <- i + 1
y.pred[sample] <- y.pred[sample] + (predict(Trees[[index]],
df.test[sample,])[2]*clusters.sizes[i]) # it's working
}
}
# now time to check performance
#roc_obj <- roc(y.test, y.pred)
#auc(roc_obj)
roc.obj <- roc(y.test, y.pred) #ROC object + call auc()
auroc <- auc(roc.obj)
#aupr <- pr.curve(scores.class0 = y.test, scores.class1 = bg, curve = F)
#aupr <- qpPrecisionRecall(y.pred, y.test)
new.data <- c(folder, auroc, aupr)
results_all <- rbind(results_all, new.data)
print(paste(auroc))
print(paste(aupr))
print(paste("done"))
#results[k] <-lapply(1:K, function(k) ETrees(df.test, k))
auroc.fold[k] <- auroc
aupr.fold[k] <- NaN #aupr
},
error =function(e) {
auroc.fold[k] <- NaN
aupr.fold[k] <- NaN
}
)
}
new.data2 <-c(folder, mean(auroc.fold, na.rm=TRUE), mean(aupr.fold, na.rm=TRUE))
results_df <- rbind(results_df, new.data2)
}
#write.csv(results_all, datapath <- "C:/Users/u0135479/Documents/GitHub/Explain-extract-trees/C443_long_results_3K_new.csv")
#write.csv(results_df, datapath <- "C:/Users/u0135479/Documents/GitHub/Explain-extract-trees/C443_results_3K_new.csv")
a = array(c(0,1,3, NaN))
print(mean(a,na.rm=TRUE))
View(results_df)
View(results_df)
debugSource("~/GitHub/Explain-extract-trees/C443_examples_from_manual.R")
install.packages("C443")
library(C443)
require(C443)
rownames(installed.packages())
require(MASS)
require(rpart)
#Function to draw a bootstrap sample from a dataset
DrawBoots <- function(dataset, i){
set.seed(2394 + i)
Boot <- dataset[sample(1:nrow(dataset), size = nrow(dataset), replace = TRUE),]
return(Boot)
}
#Function to grow a tree using rpart on a dataset
GrowTree <- function(x,y,BootsSample, minsplit = 40, minbucket = 20, maxdepth =3){
controlrpart <- rpart.control(minsplit = minsplit, minbucket = minbucket, maxdepth = maxdepth,
maxsurrogate = 0, maxcompete = 0)
tree <- rpart(as.formula(paste(noquote(paste(y, "~")), noquote(paste(x, collapse="+")))),
data = BootsSample, control = controlrpart)
return(tree)
}
#Use functions to draw 20 boostrapsamples and grow a tree on each sample
Boots<- lapply(1:10, function(k) DrawBoots(Pima.tr ,k))
Trees <- lapply(1:10, function (i) GrowTree(x=c("npreg", "glu", "bp", "skin",
"bmi", "ped", "age"), y="type", Boots[[i]] ))
#Turn the lists of dataframes and rpart trees to a forest object
ClusterForest<- clusterforest(fulldata=Pima.tr,treedata=Boots,trees=Trees,m=1,
fromclus=1, toclus=5)
require(MASS)
require(rpart)
#Function to draw a bootstrap sample from a dataset
DrawBoots <- function(dataset, i){
set.seed(2394 + i)
Boot <- dataset[sample(1:nrow(dataset), size = nrow(dataset), replace = TRUE),]
return(Boot)
}
#Function to grow a tree using rpart on a dataset
GrowTree <- function(x,y,BootsSample, minsplit = 40, minbucket = 20, maxdepth =3){
controlrpart <- rpart.control(minsplit = minsplit, minbucket = minbucket, maxdepth = maxdepth,
maxsurrogate = 0, maxcompete = 0)
tree <- rpart(as.formula(paste(noquote(paste(y, "~")), noquote(paste(x, collapse="+")))),
data = BootsSample, control = controlrpart)
return(tree)
}
#Use functions to draw 20 boostrapsamples and grow a tree on each sample
Boots<- lapply(1:10, function(k) DrawBoots(Pima.tr ,k))
Trees <- lapply(1:10, function (i) GrowTree(x=c("npreg", "glu", "bp", "skin",
"bmi", "ped", "age"), y="type", Boots[[i]] ))
#Turn the lists of dataframes and rpart trees to a forest object
ClusterForest<- clusterforest(fulldata=Pima.tr,treedata=Boots,trees=Trees,m=1,
fromclus=1, toclus=5)
sessionInfo()
View(ETrees)
View(ETrees)
View(Trees)
.libPaths()
.libPaths()
debugSource("~/GitHub/Explain-extract-trees/C443_single_data_single_fold.R")
source("~/GitHub/Explain-extract-trees/C443_examples_from_manual.R")
source("~/GitHub/Explain-extract-trees/C443_examples_from_manual.R")
source("~/GitHub/Explain-extract-trees/C443_examples_from_manual.R")
require(MASS)
require(rpart)
require(C443)
require(rpart)
#Function to draw a bootstrap sample from a dataset
DrawBoots <- function(dataset, i){
set.seed(2394 + i)
Boot <- dataset[sample(1:nrow(dataset), size = nrow(dataset), replace = TRUE),]
return(Boot)
}
#Function to grow a tree using rpart on a dataset
GrowTree <- function(x,y,BootsSample, minsplit = 40, minbucket = 20, maxdepth =3){
controlrpart <- rpart.control(minsplit = minsplit, minbucket = minbucket, maxdepth = maxdepth,
maxsurrogate = 0, maxcompete = 0)
tree <- rpart(as.formula(paste(noquote(paste(y, "~")), noquote(paste(x, collapse="+")))),
data = BootsSample, control = controlrpart)
return(tree)
}
#Use functions to draw 20 boostrapsamples and grow a tree on each sample
Boots<- lapply(1:10, function(k) DrawBoots(Pima.tr ,k))
Trees <- lapply(1:10, function (i) GrowTree(x=c("npreg", "glu", "bp", "skin",
"bmi", "ped", "age"), y="type", Boots[[i]] ))
1+1
#Turn the lists of dataframes and rpart trees to a forest object
ClusterForest<- clusterforest(fulldata=Pima.tr,treedata=Boots,trees=Trees,m=1,
fromclus=1, toclus=5)
require(C443)
require(MASS)
require(rpart)
#Function to draw a bootstrap sample from a dataset
DrawBoots <- function(dataset, i){
set.seed(2394 + i)
Boot <- dataset[sample(1:nrow(dataset), size = nrow(dataset), replace = TRUE),]
return(Boot)
}
#Function to grow a tree using rpart on a dataset
GrowTree <- function(x,y,BootsSample, minsplit = 40, minbucket = 20, maxdepth =3){
controlrpart <- rpart.control(minsplit = minsplit, minbucket = minbucket,
maxdepth = maxdepth, maxsurrogate = 0, maxcompete = 0)
tree <- rpart(as.formula(paste(noquote(paste(y, "~")),
noquote(paste(x, collapse="+")))), data = BootsSample,
control = controlrpart)
return(tree)
}
#Use functions to draw 20 boostrapsamples and grow a tree on each sample
Boots<- lapply(1:10, function(k) DrawBoots(Pima.tr ,k))
Trees <- lapply(1:10, function (i) GrowTree(x=c("npreg", "glu", "bp",
"skin", "bmi", "ped", "age"), y="type",
Boots[[i]] ))
ClusterForest<- clusterforest(fulldata=Pima.tr,treedata=Boots,trees=Trees,m=1,
fromclus=1, toclus=5)
plot(ClusterForest)
plot(ClusterForest,2)
debugSource("~/GitHub/Explain-extract-trees/C443_examples_from_manual.R")
1
debugSource("~/GitHub/Explain-extract-trees/C443_examples_from_manual.R")
install.packages("MASS")
install.packages("MASS")
library(C443)
library(MASS)
debugSource("~/GitHub/Explain-extract-trees/C443_examples_from_manual.R")
install.packages("MASS")
install.packages("MASS")
require(MASS)
debugSource("~/GitHub/Explain-extract-trees/C443_examples_from_manual.R")
require(MASS)
require(C443)
require(rpart)
#Function to draw a bootstrap sample from a dataset
DrawBoots <- function(dataset, i){
set.seed(2394 + i)
Boot <- dataset[sample(1:nrow(dataset), size = nrow(dataset), replace = TRUE),]
return(Boot)
}
#Function to grow a tree using rpart on a dataset
GrowTree <- function(x,y,BootsSample, minsplit = 40, minbucket = 20, maxdepth =3){
controlrpart <- rpart.control(minsplit = minsplit, minbucket = minbucket, maxdepth = maxdepth,
maxsurrogate = 0, maxcompete = 0)
tree <- rpart(as.formula(paste(noquote(paste(y, "~")), noquote(paste(x, collapse="+")))),
data = BootsSample, control = controlrpart)
return(tree)
}
#Use functions to draw 20 boostrapsamples and grow a tree on each sample
Boots<- lapply(1:10, function(k) DrawBoots(Pima.tr ,k))
Trees <- lapply(1:10, function (i) GrowTree(x=c("npreg", "glu", "bp", "skin",
"bmi", "ped", "age"), y="type", Boots[[i]] ))
#Turn the lists of dataframes and rpart trees to a forest object
ClusterForest<- clusterforest(fulldata=Pima.tr,treedata=Boots,trees=Trees,m=1,
fromclus=1, toclus=5)
require(MASS)
require(C443)
require(rpart)
debugSource("~/GitHub/Explain-extract-trees/C443_examples_from_manual.R")
debugSource("~/GitHub/Explain-extract-trees/C443_examples_from_manual.R")
debugSource("~/GitHub/Explain-extract-trees/C443_examples_from_manual.R")
debugSource("~/GitHub/Explain-extract-trees/C443_examples_from_manual.R")
require(pROC) # for the AUROC part
install.packages("pROC")
install.packages("installr")
library(installr)
updateR()
source("~/GitHub/Explain-extract-trees/C443_single_data_single_fold.R")
debugSource("~/GitHub/Explain-extract-trees/C443_single_data_single_fold.R")
debugSource("~/GitHub/Explain-extract-trees/C443_single_data_single_fold.R")
install.packages(c("class", "foreign", "MASS", "Matrix", "nlme", "nnet", "rlang", "rpart", "spatial"))
install.packages(c("class", "foreign", "MASS", "Matrix", "nlme", "nnet", "rlang", "rpart", "spatial"))
install.packages(c("class", "foreign", "MASS", "Matrix", "nlme", "nnet", "rlang", "rpart", "spatial"))
install.packages(c("class", "foreign", "MASS", "Matrix", "nlme", "nnet", "rlang", "rpart", "spatial"))
install.packages(c("class", "foreign", "MASS", "Matrix", "nlme", "nnet", "rlang", "rpart", "spatial"))
source("~/GitHub/Explain-extract-trees/C443_single_data_single_fold.R")
debugSource("~/GitHub/Explain-extract-trees/C443_single_data_single_fold.R")
Q
1+1
debugSource("~/GitHub/Explain-extract-trees/C443_single_data_single_fold.R")
debugSource("~/GitHub/Explain-extract-trees/C443_single_data_single_fold.R")
debugSource("~/GitHub/Explain-extract-trees/C443_single_data_single_fold.R")
debugSource("~/GitHub/Explain-extract-trees/C443_single_data_single_fold.R")
debugSource("~/GitHub/Explain-extract-trees/C443_single_data_single_fold.R")
n
debugSource("~/GitHub/Explain-extract-trees/C443_single_data_single_fold.R")
n
debugSource("~/GitHub/Explain-extract-trees/C443_single_data_single_fold.R")
tree <- Trees[[1]]
View(tree)
tree$frame
############################################
### German Credit Application
############################################
#--- Setup ----
# To run MOC
# load `iml` and `counterfactuals` like "normal" packages.
# in the future this would just be library("counterfactuals").
devtools::load_all("../iml", export_all = FALSE)
devtools::load_all("../counterfactuals", export_all = FALSE)
library("mlr")
library("mlrCPO")
library("ggplot2")
best.params = readRDS("../saved_objects/best_configs.rds")  # generated by irace in folder appendix_irace
USE_TRAINED_MODEL = TRUE
PARALLEL = TRUE
###---- Get data ----
credit = read.csv("german_credit_data.csv", row.names = 1, stringsAsFactors = TRUE)
names(credit)
# omit rows with NA entries
credit = na.omit(credit)
# join groups with small frequencies
levels(credit$Purpose) = c("others", "car", "others", "others",
"furniture", "radio/TV", "others", "others")
levels(credit$Saving.accounts) = c("little", "moderate", "rich", "rich")
# Colnames to lower
names(credit) = tolower(names(credit))
# Drop levels
credit = droplevels.data.frame(credit)
###---- Define xinterest and training/test data ----
# Separate xinterest from training dataset
x.interest = credit[1,]
credit = credit[-1,]
###---- Train model ----
if (USE_TRAINED_MODEL) {
credit.model = readRDS("model_svm.rds")
} else {
credit.task = makeClassifTask(id = "credit",
data = credit, target = "risk")
lrn = makeLearner("classif.svm", predict.type = "prob")
credit.lrn = cpoScale() %>>% cpoDummyEncode() %>>% lrn
param.set = pSS(
cost: numeric[0.01, 1]
)
TUNEITERS = 100L
RESAMPLING = cv5
if (PARALLEL) {
parallelMap::parallelStartSocket(parallel::detectCores(), level = "mlr.tuneParams")
}
ctrl = makeTuneControlRandom(maxit = TUNEITERS * length(param.set$pars))
lrn.tuning = makeTuneWrapper(lrn, RESAMPLING, list(mlr::acc), param.set, ctrl, show.info = FALSE)
res = tuneParams(lrn, credit.task, RESAMPLING, par.set = param.set, control = ctrl,
show.info = FALSE)
performance = resample(lrn.tuning, credit.task, RESAMPLING, list(mlr::acc))$aggr
if (PARALLEL) {
parallelMap::parallelStop()
}
credit.lrn = setHyperPars2(credit.lrn, res$x)
credit.model = mlr::train(credit.lrn, credit.task)  # use mlr:: in case caret is loaded somewhere
}
pred = Predictor$new(model = credit.model, data = credit, class = "good",
conditional = FALSE)
ctr = partykit::ctree_control(maxdepth = 5L)
set.seed(1234)
pred$conditionals = fit_conditionals(pred$data$get.x(), ctrl = ctr)
###---- Compute counterfactuals ----
pred$predict(x.interest)
set.seed(1000)
system.time({credit.cf = Counterfactuals$new(predictor = pred,
x.interest = x.interest,
target = c(0.5, 1), epsilon = 0, generations = list(mosmafs::mosmafsTermStagnationHV(10),
mosmafs::mosmafsTermGenerations(200)),
mu = best.params$mu,
p.mut = best.params$p.mut, p.rec = best.params$p.rec,
p.mut.gen = best.params$p.mut.gen,
p.mut.use.orig = best.params$p.mut.use.orig,
p.rec.gen = best.params$p.rec.gen, initialization = "icecurve",
p.rec.use.orig = best.params$p.rec.use.orig)})
# Number of counterfactuals
nrow(credit.cf$results$counterfactuals)
id = credit.cf$results$counterfactuals$dist.target == 0
sum(id)
# Focus counterfactuals that met target
credit.cf$results$counterfactuals = credit.cf$results$counterfactuals[which(id), ]
credit.cf$results$counterfactuals.diff = credit.cf$results$counterfactuals.diff[which(id), ]
# Get relative frequency of feature changes
credit.cf$get_frequency()
###---- Plots ----
a = credit.cf$plot_parallel(features = c("duration", "credit.amount"), plot.x.interest = FALSE)
a = a + scale_x_discrete(expand = c(0.1, 0.1), labels= c("duration", "credit amount"))
a
b = credit.cf$plot_surface(features = c("duration", "credit.amount"))
b
c = credit.cf$plot_hv()
c
# ggsave("credit_parallel.pdf", plot = a, width= 3, height = 2.5)
# ggsave("credit_heat.pdf", plot = b, width= 4, height = 2.5)
# ggsave("credit_hv.pdf", plot = c, width= 3.5, height = 2)
############################################
### German Credit Application
############################################
#--- Setup ----
# To run MOC
# load `iml` and `counterfactuals` like "normal" packages.
# in the future this would just be library("counterfactuals").
devtools::load_all("../iml", export_all = FALSE)
devtools::load_all("../counterfactuals", export_all = FALSE)
library("mlr")
library("mlrCPO")
library("ggplot2")
############################################
### German Credit Application
############################################
#--- Setup ----
# To run MOC
# load `iml` and `counterfactuals` like "normal" packages.
# in the future this would just be library("counterfactuals").
devtools::load_all("../iml", export_all = FALSE)
devtools::load_all("../counterfactuals", export_all = FALSE)
library("mlr")
library("mlrCPO")
library("ggplot2")
library("mlr")
library("mlrCPO")
library("ggplot2")
#--- Setup ----
# To run MOC
# load `iml` and `counterfactuals` like "normal" packages.
# in the future this would just be library("counterfactuals").
devtools::load_all("../iml", export_all = FALSE)
devtools::load_all("../counterfactuals", export_all = FALSE)
df <- data(udca, package="survival")
df2 <- data(udca2, package="survival")
install.packages("survival")
install.packages("survival")
df <- data(udca, package="survival")
df <- data(udca, package="survival")
df2 <- data(udca2, package="survival")
df <- data(udca1, package="survival")
data("udca", package="survival")
force(udca)
df1 <- data("udca", package="survival")
data("udca", package="survival")
data("udca2", package="survival")
library("survival")
data("udca", package="survival")
data("udca2", package="survival")
source("~/appsecurityexcluded/R_Scripts/load_me_survival.R")
source("~/appsecurityexcluded/R_Scripts/load_me_survival.R")
library("survival")
data("udca", package="survival")
data("udca2", package="survival")
library("survival")
data("udca", package="survival")
head(udca)
head(udca2)
head(udca$futime)
udca$futime
head(udca1$futime)
head(udca1$status)
getwd()
library("survival")
data("udca", package="survival")
data("udca2", package="survival")
#
# head(udca)
# head(udca2)
head(udca1$futime)
head(udca1$status)
setwd("C:/Users/u0135479/Documents/GitHub/Bellatrex/datasets/me_survival")
write.csv(udca, "udca.csv", row.names = FALSE)
write.csv(udca1, "udca1.csv", row.names = FALSE)
write.csv(udca2, "udca2.csv", row.names = FALSE)
1+1
install.packages("semiCompRisks")
install.packages("SemiCompRisks")
library("survival")
library("SemiCompRisks")
data("udca", package="survival")
data("udca2", package="survival")
#
# head(udca)
# head(udca2)
head(udca1$futime)
head(udca1$status)
setwd("C:/Users/u0135479/Documents/GitHub/Bellatrex/datasets/me_survival")
#
# write.csv(udca, "udca.csv", row.names = FALSE)
# write.csv(udca1, "udca1.csv", row.names = FALSE)
# write.csv(udca2, "udca2.csv", row.names = FALSE)
# Define sample size and other parameters
n <- 200
alpha <- c(-6, -2)
beta <- c(-0.5, 0.5)
lambda <- 0.1
rho <- 0
# Generate the dataset
set.seed(1) # for reproducibility
data <- semiCmpRisk(n = n, lambda = lambda, rho = rho, alpha = alpha, beta = beta)
data <- semiCompRisk(n = n, lambda = lambda, rho = rho, alpha = alpha, beta = beta)
